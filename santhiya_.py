# -*- coding: utf-8 -*-
"""santhiya .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XrDsCoZFlvp5wes3zvNyX1kihAIuQRip
"""

#TASK1
print("Hello ,Excited to Start Data Science")



customer_name = "John Doe"
customer_age = 28
customer_balance = 120.75
print("customer:",customer_name)
print("age:",customer_age)
print("Balance:",customer_balance)

product_price = 200
discount = product_price* 0.10
final_price = product_price - discount
print("Final price after Discount:",final_price)

import numpy as np
sales = np.array([150,200,250,300,400,350,500])
print("sales Data:",sales)

print("Average Sales:",np.mean(sales))
print("Highest sale:",np.max(sales))
print("Lowest sale:",np.min(sales))

import pandas as pd
data = {"customer":["Alice","Bob","Charile"],"Age":[25,30,35],"Amount Spent":[120,200,150]}
df = pd.DataFrame(data)
print(df)

high_spenders = df[df["Amount Spent"]>130]
print(high_spenders)

df_sorted = df.sort_values(by="Amount Spent",ascending=True)
print(df_sorted)

import pandas as pd
data = {"Customer":["Alice","Bob","Charile"],"Age":[25,30,35],"Amount Spent":[120,200,150]}
df = pd.DataFrame(data)
print(df)
from google.colab import files
df.to_csv("data.csv",index=False)
files.download("data.csv")

from google.colab import files
uploaded = files.upload()
df = pd.read_csv("data.csv")
df.head()

df["Loyalty points"] = df["Amount Spent"]//10
df

#DAY5
# MATPLOTLIB#line plot
import matplotlib.pyplot as plt
import numpy as np
x = np.linspace(0,10,100)
y = np.sin(x)
plt.plot(x,y,label="sine wave")
plt.xlabel("X axis")
plt.ylabel("Y axis")
plt.title("Simple Line Plot")
plt.legend()
plt.show()

#bar plot
import matplotlib.pyplot as plt
import numpy as np
categories = ['A','B','C','D']
values = [10,25,15,30]
plt.figure(figsize=(6,4))
plt.bar(categories, values, color='purple')
plt.xlabel("categories")
plt.ylabel("Values")
plt.title("Bar Chart Example")
plt.show()

#HISTROGRAM
data=np.random.randn(1000)
plt.figure(figsize=(7,5))
plt.hist(data,bins=30, color='green',edgecolor='black',alpha=0.7)
plt.xlabel("value")
plt.ylabel("Freqency")
plt.title("Histogram Example")
plt.show()

import seaborn as sns
import pandas as pd
import numpy as np # Import the numpy library and assign it to the alias 'np'
data=np.random.randn(1000)
df=pd.DataFrame(data,columns=['Values'])
sns.histplot(df['Values'], bins=30, kde=True, color='blue') # Changed 'bule' to 'blue'
plt.title("histogram with KDE")
plt.show()

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt # Import the matplotlib library and assign it to the alias 'plt'

tips=sns.load_dataset('tips')
plt.figure(figsize= (6,4))
sns.boxplot(x=tips['total_bill'])
plt.title("Box plot of Total Bill")
plt.show()

sns.pairplot(tips,hue='sex')
plt.show()

# Convert categorical columns to numerical representations before calculating correlation
tips['sex'] = tips['sex'].map({'Female': 0, 'Male': 1})  # Example for 'sex' column
tips['smoker'] = tips['smoker'].map({'No': 0, 'Yes': 1}) # Example for 'smoker' column
tips['day'] = tips['day'].map({'Thur': 0, 'Fri': 1, 'Sat': 2, 'Sun': 3}) # Example for 'day' column
tips['time'] = tips['time'].map({'Lunch': 0, 'Dinner': 1}) # Example for 'time' column

corr_matrix = tips.corr()
plt.figure(figsize=(7,5))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

#pyplot
import plotly.express as px
import pandas as pd
import numpy as np
df = pd.DataFrame({"x": np.linspace(0, 10, 100), "y": np.sin(np.linspace(0, 10, 100))})
fig = px.line(df, x="x", y="y", title="Interactive Sine Wave")
fig.show()

import plotly.express as px
import seaborn as sns
tips = sns.load_dataset('tips')
fig = px.scatter(tips, x='total_bill', y='tip', color='sex', size='size', title="Total Bill vs Tip")
fig.show()

import plotly.graph_objects as go
fig = go.Figure(data=[go.Scatter3d(x=tips['total_bill'], y=tips['tip'], z=tips['size'],mode='markers',marker=dict(size=5, color=tips['total_bill'], colorscale='viridis'))]) # Changed go.scatter3d to go.Scatter3d and mode='markets' to mode='markers' and market to marker
fig.update_layout(title="3D Scatter plot of Total Bill,Tip & Size")
fig.show()

#DAY2
import numpy as np
import pandas as pd
from google.colab import files
uploaded = files.upload()
df = pd.read_csv("students_dataset.csv")
df

print(df.isnull().sum())

df_cleaned = df.dropna()
print(df_cleaned)

print(df_cleaned.isnull().sum())

df["Age"].fillna(df["Age"].mean(),inplace=True)
df["Marks"].fillna(df["Marks"].median(),inplace=True)
df["Attendance"].fillna(df["Attendance"].mean(),inplace=True)
df["Passed"].fillna(df["Passed"].mode()[0],inplace=True)
print(df) # Changed 'ptint' to 'print'

df.ffill(inplace=True)
df.bfill(inplace=True)
print(df)

df.drop_duplicates(inplace=True)
print("Removed Duplicate Successfully...")

from sklearn.preprocessing import StandardScaler # Changed standardscaler to StandardScaler
scaler = StandardScaler()
df_scaled = df.copy()
df_scaled[["Marks","Attendance"]] = scaler.fit_transform(df[["Marks","Attendance"]])
print(df_scaled)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df_scaled = df.copy()
df_scaled[["Marks","Attendance"]] = scaler.fit_transform(df[["Marks","Attendance"]])
print(df_scaled)

df_encoded = pd.get_dummies(df,columns=["Passed"],drop_first=True) # Changed 'passed' to 'Passed'
print(df_encoded)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df["Passed"] = encoder.fit_transform(df["Passed"]) # Changed 'fit_transfrom' to 'fit_transform'
print(df)

def performance_category(marks):
  if marks >=85:
    return "High"
  elif marks >=70:
    return "Medium"
  else:
    return "Low"

df["Performance"] = df["Marks"].apply(performance_category)
print(df)

import numpy as np
import pandas as pd
from scipy import stats
data = [10,20,30,40,50,60,70,80,90,100]
mean_value = np.mean(data)
print(f"Mean:{mean_value}")

variance = np.var(data, ddof=1)
std_dev = np.std(data,ddof=1)
print(f"Variance:{variance}")
print(f"Standard Deviation:{std_dev}")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
data={'Math':[80,85,78,90,88,92,76,89,95,84],'Science':[75,82,79,91,87,95,72,88,97,83],'english':[85,80,78,88,90,85,76,89,92,81]}
df = pd.DataFrame(data)
correlation_matrix = df.corr()
plt.figure(figsize=(6,4))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm",fmt=".2f")
plt.title("student scores correlation Heatmap")
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
data = [10,12,14,15,17,20,30,100]
df=pd.DataFrame(data,columns=['values'])
Q1=df['values'].quantile(0.25)
Q3=df['values'].quantile(0.75)
IQR=Q3-Q1
lower_bound=Q1-1.5*IQR
upper_bound=Q3+1.5*IQR
outliers = df[(df['values']<lower_bound)|(df['values']>upper_bound)]
plt.boxplot(df['values'])
plt.title("Box plot to Detect Outliers")
plt.show()
print("Outliers:\n",outliers)

data_array=np.array(data)
z_scores= np.abs(stats.zscore(data_array))
outliers = data_array[z_scores>3]
print("Outliers using z-score method:",outliers)

plt.scatter(range(len(data)),data,color='blue',label="Data Points")
plt.scatter([data.index(100)],[100],color='red',label="outliers")
plt.xlabel("Index")
plt.ylabel("Values")
plt.title("scatter plot showing outliers")
plt.legend()
plt.show()

import pandas as pd
data=pd.DataFrame({'Category':['Apple','Banana','Apple','Orange','Banana','Apple']})
print(data['Category'].value_counts())
print(data['Category'].value_counts(normalize=True)*100)

import matplotlib.pyplot as plt
import seaborn as sns
categories = ['Apple','Banana','Apple','Orange','Banana','Apple']
df=pd.DataFrame({'Category':categories})
df['Category'].value_counts().plot(kind='bar',color=['red','yellow','orange'])
plt.xlabel("Category")
plt.ylabel("Count")
plt.title("Bar Plot of Categorical Data")
plt.show()
sns.countplot(x=df['Category'],palette="pastel")
plt.title("Count Plot of Categorical Data")
plt.show()

from sklearn.preprocessing import LabelEncoder,OneHotEncoder
df=pd.DataFrame({'Fruit':['Apple','Banana','Orange','Apple','Banana']})
label_encoder = LabelEncoder()
df['Fruit_Label']=label_encoder.fit_transform(df['Fruit'])
print(df)
df_one_hot = pd.get_dummies(df['Fruit'])
print(df_one_hot)

!pip install ydata_profiling
import pandas as pd
from ydata_profiling import ProfileReport
df=pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv")
profile = ProfileReport(df,explorative=True)
profile.to_notebook_iframe()
import pandas as pd
from ydata_profiling import ProfileReport
df=pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv")
profile = ProfileReport(df,explorative=True)
profile.to_notebook_iframe()
profile.to_file("titanic_report.html")

# Import required libraries
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# Load the MNIST dataset (handwritten digits 0-9)
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize the data (pixel values between 0 and 1)
x_train, x_test = x_train / 255.0, x_test / 255.0

# Reshape data to add a channel dimension (since images are grayscale)
x_train = x_train.reshape((-1, 28, 28, 1))
x_test = x_test.reshape((-1, 28, 28, 1))

# Build the CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)

# Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"\nTest Accuracy: {test_accuracy:.4f}")

# Plot training & validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('CNN Training and Validation Accuracy')
plt.show()

# Make predictions
predictions = model.predict(x_test)

# Show some test images with predicted labels
for i in range(5):
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Predicted: {predictions[i].argmax()}, Actual: {y_test[i]}")
    plt.show()